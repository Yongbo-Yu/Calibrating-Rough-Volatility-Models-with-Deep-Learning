{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_parameter(n_samples, model_name='heston'):\n",
    "    params = {}\n",
    "    if model_name == 'heston':\n",
    "        params = {\n",
    "            'eta': 5 * np.random.rand(n_samples),\n",
    "            'rho': -1 * np.random.rand(n_samples),\n",
    "            'lambda': 10 * np.random.rand(n_samples),\n",
    "            'var_avg': np.random.rand(n_samples),\n",
    "            'var_init': np.random.rand(n_samples)\n",
    "        }\n",
    "    elif model_name == 'rbergomi':\n",
    "        # truncated normal\n",
    "        # a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "        params = {\n",
    "            'eta': truncnorm.rvs(-3, 3, 2.5, 0.5, n_samples), # [1, 4, 2.5, 0.5]\n",
    "            'rho': truncnorm.rvs(-0.25, 2.25, -0.95, 0.2, n_samples), # [-1, -0.5, -0.95, 0.2]\n",
    "            'H': truncnorm.rvs(-1.2, 8.6, 0.07, 0.05, n_samples), # [0.01, 0.5, 0.07, 0.05]\n",
    "            'var_init': truncnorm.rvs(-2.5, 7, 0.3, 0.1, n_samples) # [0.05, 1, 0.3, 0.1]\n",
    "            # TODO: what does the squared mean\n",
    "        }\n",
    "    return params\n",
    "\n",
    "def param_initializer(model_name='heston'):\n",
    "    params = {}\n",
    "    if model_name == 'heston':\n",
    "        params = {\n",
    "            'eta': 5 * np.random.rand(),\n",
    "            'rho': -1 * np.random.rand(),\n",
    "            'lambda': 10 * np.random.rand(),\n",
    "            'var_avg': np.random.rand(),\n",
    "            'var_init': np.random.rand()\n",
    "        }\n",
    "    elif model_name == 'rbergomi':\n",
    "        # truncated normal\n",
    "        # a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std\n",
    "        params = {\n",
    "            'eta': truncnorm.rvs(-3, 3, 2.5, 0.5), # [1, 4, 2.5, 0.5]\n",
    "            'rho': truncnorm.rvs(-0.25, 2.25, -0.95, 0.2), # [-1, -0.5, -0.95, 0.2]\n",
    "            'H': truncnorm.rvs(-1.2, 8.6, 0.07, 0.05), # [0.01, 0.5, 0.07, 0.05]\n",
    "            'var_init': truncnorm.rvs(-2.5, 7, 0.3, 0.1) # [0.05, 1, 0.3, 0.1]\n",
    "            # TODO: what does the squared mean\n",
    "        }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_information(n_samples):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(n_samples, model='heston'):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "        n_samples: integer, number of samples to generate\n",
    "        model: str, the name of the model, 'heston' or 'rbergomi'\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        X: input data\n",
    "        Y: lables\n",
    "    \"\"\"\n",
    "    X = None\n",
    "    Y = None\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train, *X_others):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    scaled = [X_train_scaled]\n",
    "    for X in X_others:\n",
    "        scaled.append(scaler.transform(X))\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = ...\n",
    "model = K.models.Sequential(\n",
    "    K.layers.Dense(n1, activation='relu'),\n",
    "    K.layers.BatchNormalization(),\n",
    "    K.layers.Dense(1, activation='relu'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_point = ModelCheckpoint('./models/', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=2, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=50, verbose=0, validation_data=(X_val, Y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_calibration(nn, jacobian, weights, market_quotes, market_info, model_name, lambd_init, max_iter, tol, beta0, beta1):\n",
    "    # initialize\n",
    "    mu = param_initializer(model_name)\n",
    "    lambd = lambd_init\n",
    "    param_names = mu.keys()\n",
    "    mu = mu.values()\n",
    "    m = len(mu)\n",
    "    W = np.diag(weights)\n",
    "    I = np.eye(m)\n",
    "    n = 0\n",
    "    # predict\n",
    "    R = nn.predict(...) - Q # TODO\n",
    "    J = None # TODO\n",
    "    J_W = J.T.dot(W)\n",
    "    delta_mu = np.linalg.pinv(J_W.dot(J) + lambd * I).dot(J_W.dot(R)) # vector size: [m, ]\n",
    "    while n < max_iter and np.linalg.norm(delta_mu) > tol:\n",
    "        mu_new = mu + delta_mu\n",
    "        R_new = nn.predict(...) - Q # TODO\n",
    "        R_norm = np.linalg.norm(R)\n",
    "        c_mu = (R_norm - np.linalg.norm(R_new)) / (R_norm - np.linalg.norm(R + J.dot(delta_mu)))\n",
    "        if c_mu <= beta0:\n",
    "            # reject delta_mu\n",
    "            lambd *= 2 # too slow, use greater lambd\n",
    "        else:\n",
    "            # accept delta_mu\n",
    "            mu += delta_mu\n",
    "            R = R_new\n",
    "            J = None # TODO\n",
    "            J_W = J.T.dot(W)\n",
    "        if c_mu >= beta1:\n",
    "            lambd /= 2 # too quick, use smaller lambd\n",
    "        delta_mu = np.linalg.pinv(J_W.dot(J) + lambd * I).dot(J_W.dot(R)) # vector size: [m, ]\n",
    "        n += 1\n",
    "    return dict(zip(param_names, mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一篇论文里没看懂的问题\n",
    "\n",
    "1. 式（2）里的model parameters $\\mu$ 是指的模型的参数，也就是说对Heston模型，$\\mu$ 就是Table 1 里的 $(\\eta, \\rho, \\lambda, \\bar{v}, v_0)$ ；对rBergomi模型就是 $(\\eta, \\rho, H, v_0)$ 。是这样吗？\n",
    "2. Market information $\\xi$ 怎么得到？是跟 $\\mu$ 一样按照某个分布随机生成吗？同理，$(M, T)$ 是怎么得到的？论文第11页上面那一部分讲的是参数生成，但我看不太懂。\n",
    "3. 第11页第二段说\"increase the number of samples in option parameter regions with high liquidity ...\"， 这一段我也看不懂。\n",
    "4. 你们谁有时间能不能研究一下QuantLib这个package，看看用来生成Heston模型数据应该调用哪个函数？我研究了一下，但没有Finance的知识背景很难理解那些函数和函数的参数是什么意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
